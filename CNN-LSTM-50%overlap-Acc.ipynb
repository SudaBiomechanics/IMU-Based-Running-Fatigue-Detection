{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN-LSTM自己"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1  as tf\n",
    "import numpy as np\n",
    "import os,sys\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import scipy.io as scio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34334, 200, 9)\n",
      "(34334, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_mat = scio.loadmat('X_train-3Classes-50%overlap.mat')\n",
    "key_name = list(X_train_mat.keys())[-1]\n",
    "X_train=X_train_mat[key_name]\n",
    "print(X_train.shape)\n",
    "\n",
    "Y_train_mat = scio.loadmat('Y_train-3Classes-50%overlap.mat')\n",
    "key_name = list(Y_train_mat.keys())[-1]\n",
    "Y_train=Y_train_mat[key_name]\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34334, 200, 3)\n",
      "(34334, 1)\n"
     ]
    }
   ],
   "source": [
    "#只取前列数据\n",
    "X_train=X_train[:,:,0:3]#只取前\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30900, 200, 3)\n",
      "(30900, 1)\n",
      "(3434, 200, 3)\n",
      "(3434, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 0)\n",
    "#X_test, X_valid, Y_test, Y_valid = train_test_split(X_test, Y_test, test_size = 0.5, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(42)\n",
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import regularizers,Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Flatten, Reshape, Softmax,concatenate\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, TimeDistributed,LSTM,Bidirectional,BatchNormalization\n",
    "from keras.models import Model\n",
    "#from keras import backend as K\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# callbacks:\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 3 30900\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Initializing parameters\n",
    "epochs = 200\n",
    "batch_size = 256\n",
    "timesteps = 200\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "#input_shape = (timesteps, input_dim)\n",
    "\n",
    "print(timesteps,input_dim,len(X_train))\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp=Input(shape=(200,3))\n",
    "\n",
    "    #CNN model\n",
    "    reshape=Reshape((200,3,1))(inp)\n",
    "    conv1=Conv2D(32,(18,1),activation='relu',strides=(2,1),padding='SAME',input_shape=(200,3,1))(reshape)\n",
    "    maxp1=MaxPooling2D(pool_size=(2, 1))(conv1)\n",
    "    conv2=Conv2D(64, (9, 1), activation='relu',padding='SAME')(maxp1)\n",
    "    conv3=Conv2D(128, (3, 1), activation='relu',padding='SAME')(conv2)\n",
    "    maxp3=MaxPooling2D(pool_size=(2, 1))(conv3)\n",
    "    conv4=Conv2D(128, (1, 3), activation='relu', padding='VALID')(maxp3)\n",
    "    cnn_out=Flatten()(conv4)\n",
    "\n",
    "\n",
    "    #LSTM model\n",
    "    lstm1=LSTM(64, return_sequences=True, input_shape=(timesteps, input_dim), kernel_initializer='glorot_normal')(inp)\n",
    "    # Adding a dropout layer\n",
    "    #model2.add(Dropout(0.25))\n",
    "    batch1=BatchNormalization()(lstm1)\n",
    "    lstm2=LSTM(64)(batch1)\n",
    "    # Adding a dropout layer\n",
    "    lstm_out=Dropout(0.5)(lstm2)\n",
    "\n",
    "    m2=concatenate([cnn_out,lstm_out],axis=1)\n",
    "\n",
    "    m2_out=Dense(n_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01),\n",
    "                    activity_regularizer=regularizers.l1(0.01))(m2)\n",
    "    model=Model(inputs=inp,outputs=m2_out)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 200, 3)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 200, 3, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 100, 3, 32)   608         reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 50, 3, 32)    0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 50, 3, 64)    18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 50, 3, 128)   24704       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 200, 64)      17408       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 25, 3, 128)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 200, 64)      256         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 25, 1, 128)   49280       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 64)           33024       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3200)         0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3264)         0           flatten[0][0]                    \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            9795        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 153,571\n",
      "Trainable params: 153,443\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#-------------------\n",
    "# Compiling the model\n",
    "model=get_model()\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "filepath=\"M2-weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "mc = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',  # log 目录\n",
    "                 histogram_freq=1,  # 按照何等频率（epoch）来计算直方图，0为不计算\n",
    "                 batch_size=64,     # 用多大量的数据计算直方图\n",
    "                 write_graph=True,  # 是否存储网络结构图\n",
    "                 write_grads=True, # 是否可视化梯度直方图\n",
    "                 write_images=True,# 是否可视化参数\n",
    "                 embeddings_freq=0,\n",
    "                 embeddings_layer_names=None,\n",
    "                 embeddings_metadata=None)\n",
    "\n",
    "es=EarlyStopping(monitor='val_loss', patience=14, verbose=2)\n",
    "rp=ReduceLROnPlateau(\n",
    "    monitor='val_acc',\n",
    "    factor=0.25,\n",
    "    patience=8,#多少epoch，如果monitor内容没有效果就earlystop\n",
    "    verbose=2,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0\n",
    ")\n",
    "\n",
    "# callbacks_list = [mc,tb,es,rp]\n",
    "callbacks_list = [mc,es,rp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27810 samples, validate on 3090 samples\n",
      "Epoch 1/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 1.2408 - acc: 0.4705WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.44854, saving model to M2-weights-improvement-01-0.45.hdf5\n",
      "27810/27810 [==============================] - 182s 7ms/sample - loss: 1.2408 - acc: 0.4705 - val_loss: 1.0473 - val_acc: 0.4485\n",
      "Epoch 2/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.8381 - acc: 0.6029\n",
      "Epoch 00002: val_acc improved from 0.44854 to 0.66828, saving model to M2-weights-improvement-02-0.67.hdf5\n",
      "27810/27810 [==============================] - 181s 6ms/sample - loss: 0.8381 - acc: 0.6029 - val_loss: 0.7145 - val_acc: 0.6683\n",
      "Epoch 3/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.6711 - acc: 0.7011\n",
      "Epoch 00003: val_acc improved from 0.66828 to 0.75566, saving model to M2-weights-improvement-03-0.76.hdf5\n",
      "27810/27810 [==============================] - 168s 6ms/sample - loss: 0.6711 - acc: 0.7011 - val_loss: 0.5939 - val_acc: 0.7557\n",
      "Epoch 4/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.5638 - acc: 0.7597\n",
      "Epoch 00004: val_acc improved from 0.75566 to 0.81650, saving model to M2-weights-improvement-04-0.82.hdf5\n",
      "27810/27810 [==============================] - 168s 6ms/sample - loss: 0.5638 - acc: 0.7597 - val_loss: 0.4786 - val_acc: 0.8165\n",
      "Epoch 5/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.4775 - acc: 0.8056\n",
      "Epoch 00005: val_acc did not improve from 0.81650\n",
      "27810/27810 [==============================] - 170s 6ms/sample - loss: 0.4775 - acc: 0.8056 - val_loss: 0.6368 - val_acc: 0.7320\n",
      "Epoch 6/200\n",
      "23808/27810 [========================>.....] - ETA: 25s - loss: 0.4218 - acc: 0.8337"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "#model.load_weights(\"M-weights-improvement-19-0.93.hdf5\")\n",
    "history=model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.1,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########画图\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "acc = history.history['acc']     #获取训练集准确性数据\n",
    "val_acc = history.history['val_acc']    #获取验证集准确性数据\n",
    "loss = history.history['loss']          #获取训练集错误值数据\n",
    "val_loss = history.history['val_loss']  #获取验证集错误值数据\n",
    "font = {\n",
    "    'family' : 'Bitstream Vera Sans',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "width = 12\n",
    "height = 8\n",
    "plt.figure(figsize=(width, height))\n",
    "epochs = range(1,len(acc)+1)\n",
    "plt.plot(epochs,acc,'r',label='Trainning acc',linewidth=2)     #以epochs为横坐标，以训练集准确性为纵坐标\n",
    "plt.plot(epochs,val_acc,'b--',label='Vaildation acc',linewidth=2) #以epochs为横坐标，以验证集准确性为纵坐标\n",
    "plt.legend(loc='best', shadow=True)   #绘制图例，即标明图中的线段代表何种含义\n",
    "plt.title(\"Training session's progress over epochs\")\n",
    "plt.ylabel('Training Progress (Accuracy values)')\n",
    "plt.xlabel('Training epochs')\n",
    "plt.ylim([0.6,1])\n",
    "\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.plot(epochs,loss,'r',label='Trainning loss',linewidth=2)\n",
    "plt.plot(epochs,val_loss,'b--',label='Vaildation loss',linewidth=2)\n",
    "plt.legend(loc='best', shadow=True)   #绘制图例，即标明图中的线段代表何种含义\n",
    "plt.title(\"Training session's progress over epochs\")\n",
    "plt.ylabel('Training Progress (Loss values)')\n",
    "plt.xlabel('Training epochs') \n",
    "plt.show()    #显示所有图表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.load_weights(\"M2-weights-improvement-45-0.97.hdf5\")\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# confusion matrix\n",
    "Y_pred=model.predict_classes(X_test)\n",
    "print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm_cmap=plt.cm.Greens\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "\n",
    "\n",
    "print('| Confusion Matrix |')\n",
    "print('--------------------')\n",
    "print('\\n {}'.format(cm))\n",
    "class_labels=['Pre','Mid','Post']\n",
    "# plot confusin matrix\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.grid(b=False)\n",
    "plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n",
    "plt.show()\n",
    "class_labels=[0,1,2]\n",
    "# get classification report\n",
    "print('| Classifiction Report |')\n",
    "print('-------------------------')\n",
    "classification_report = metrics.classification_report(Y_test,Y_pred,labels =class_labels)\n",
    "# store report in results\n",
    "\n",
    "\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
