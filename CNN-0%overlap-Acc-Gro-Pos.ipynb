{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Fatiuge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1  as tf\n",
    "import numpy as np\n",
    "import os,sys\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import scipy.io as scio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17174, 200, 9)\n",
      "(17174, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_mat = scio.loadmat('X_train-3Classes-0%overlap.mat')\n",
    "key_name = list(X_train_mat.keys())[-1]\n",
    "X_train=X_train_mat[key_name]\n",
    "print(X_train.shape)\n",
    "\n",
    "Y_train_mat = scio.loadmat('Y_train-3Classes-0%overlap.mat')\n",
    "key_name = list(Y_train_mat.keys())[-1]\n",
    "Y_train=Y_train_mat[key_name]\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17174, 200, 9)\n",
      "(17174, 1)\n"
     ]
    }
   ],
   "source": [
    "#只取前列数据\n",
    "X_train=X_train[:,:,0:9]#只取前\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15456, 200, 9)\n",
      "(15456, 1)\n",
      "(1718, 200, 9)\n",
      "(1718, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 0)\n",
    "#X_test, X_valid, Y_test, Y_valid = train_test_split(X_test, Y_test, test_size = 0.5, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(-1,200,9,1)\n",
    "X_test=X_test.reshape(-1,200,9,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(42)\n",
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Flatten, Reshape, Softmax\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, TimeDistributed,LSTM,Bidirectional,BatchNormalization\n",
    "#from keras import backend as K\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from attention import Attention\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# callbacks:\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 9 15456\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Initializing parameters\n",
    "epochs = 200\n",
    "batch_size = 256\n",
    "timesteps = 200\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "#input_shape = (timesteps, input_dim)\n",
    "\n",
    "print(timesteps,input_dim,len(X_train))\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 100, 9, 32)        608       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 9, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 9, 64)         18496     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 9, 128)        24704     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 4, 128)        98432     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 38403     \n",
      "=================================================================\n",
      "Total params: 180,643\n",
      "Trainable params: 180,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "input_shape = (256, 200, 9, 1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(18,1),activation='relu',strides=(2,1),padding='SAME',input_shape=(200,9,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Conv2D(64, (9, 1), activation='relu',padding='SAME'))\n",
    "model.add(Conv2D(128, (3, 1), activation='relu',padding='SAME'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Conv2D(128, (1, 6), activation='relu', padding='VALID'))\n",
    "model.add(Flatten())\n",
    "\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01)))\n",
    "\n",
    "model.summary()\n",
    "#-------------------\n",
    "# Compiling the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])#二分类：optimizer='adam', loss='binary_crossentropy'；多分类时激活函数改为softmax。损失函数改为：loss=‘categorical_crossentropy’\n",
    "\n",
    "filepath=\"CNN-weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "mc = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',  # log 目录\n",
    "                 histogram_freq=1,  # 按照何等频率（epoch）来计算直方图，0为不计算\n",
    "                 batch_size=64,     # 用多大量的数据计算直方图\n",
    "                 write_graph=True,  # 是否存储网络结构图\n",
    "                 write_grads=True, # 是否可视化梯度直方图\n",
    "                 write_images=True,# 是否可视化参数\n",
    "                 embeddings_freq=0,\n",
    "                 embeddings_layer_names=None,\n",
    "                 embeddings_metadata=None)\n",
    "\n",
    "es=EarlyStopping(monitor='val_loss', patience=16, verbose=2)\n",
    "rp=ReduceLROnPlateau(\n",
    "    monitor='val_acc',\n",
    "    factor=0.25,\n",
    "    patience=10,#\n",
    "    verbose=2,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0\n",
    ")\n",
    "\n",
    "# callbacks_list = [mc,tb,es,rp]\n",
    "callbacks_list =[mc,es,rp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13910 samples, validate on 1546 samples\n",
      "Epoch 1/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 2.7898 - acc: 0.4177WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.46960, saving model to CNN-weights-improvement-01-0.47.hdf5\n",
      "13910/13910 [==============================] - 135s 10ms/sample - loss: 2.7898 - acc: 0.4177 - val_loss: 1.0561 - val_acc: 0.4696\n",
      "Epoch 2/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.9916 - acc: 0.5130\n",
      "Epoch 00002: val_acc improved from 0.46960 to 0.59379, saving model to CNN-weights-improvement-02-0.59.hdf5\n",
      "13910/13910 [==============================] - 140s 10ms/sample - loss: 0.9916 - acc: 0.5130 - val_loss: 0.9070 - val_acc: 0.5938\n",
      "Epoch 3/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.8553 - acc: 0.6042\n",
      "Epoch 00003: val_acc did not improve from 0.59379\n",
      "13910/13910 [==============================] - 150s 11ms/sample - loss: 0.8553 - acc: 0.6042 - val_loss: 0.9590 - val_acc: 0.5336\n",
      "Epoch 4/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.7457 - acc: 0.6588\n",
      "Epoch 00004: val_acc improved from 0.59379 to 0.70505, saving model to CNN-weights-improvement-04-0.71.hdf5\n",
      "13910/13910 [==============================] - 132s 9ms/sample - loss: 0.7457 - acc: 0.6588 - val_loss: 0.6981 - val_acc: 0.7050\n",
      "Epoch 5/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.6327 - acc: 0.7370\n",
      "Epoch 00005: val_acc improved from 0.70505 to 0.80789, saving model to CNN-weights-improvement-05-0.81.hdf5\n",
      "13910/13910 [==============================] - 132s 9ms/sample - loss: 0.6327 - acc: 0.7370 - val_loss: 0.5518 - val_acc: 0.8079\n",
      "Epoch 6/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.5117 - acc: 0.8079\n",
      "Epoch 00006: val_acc improved from 0.80789 to 0.83894, saving model to CNN-weights-improvement-06-0.84.hdf5\n",
      "13910/13910 [==============================] - 130s 9ms/sample - loss: 0.5117 - acc: 0.8079 - val_loss: 0.4997 - val_acc: 0.8389\n",
      "Epoch 7/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.3745 - acc: 0.8770\n",
      "Epoch 00007: val_acc improved from 0.83894 to 0.85834, saving model to CNN-weights-improvement-07-0.86.hdf5\n",
      "13910/13910 [==============================] - 128s 9ms/sample - loss: 0.3745 - acc: 0.8770 - val_loss: 0.4210 - val_acc: 0.8583\n",
      "Epoch 8/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.2906 - acc: 0.9164\n",
      "Epoch 00008: val_acc improved from 0.85834 to 0.93208, saving model to CNN-weights-improvement-08-0.93.hdf5\n",
      "13910/13910 [==============================] - 136s 10ms/sample - loss: 0.2906 - acc: 0.9164 - val_loss: 0.2701 - val_acc: 0.9321\n",
      "Epoch 9/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.2281 - acc: 0.9393\n",
      "Epoch 00009: val_acc did not improve from 0.93208\n",
      "13910/13910 [==============================] - 135s 10ms/sample - loss: 0.2281 - acc: 0.9393 - val_loss: 0.3851 - val_acc: 0.8810\n",
      "Epoch 10/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.1917 - acc: 0.9523\n",
      "Epoch 00010: val_acc improved from 0.93208 to 0.95278, saving model to CNN-weights-improvement-10-0.95.hdf5\n",
      "13910/13910 [==============================] - 110s 8ms/sample - loss: 0.1917 - acc: 0.9523 - val_loss: 0.2114 - val_acc: 0.9528\n",
      "Epoch 11/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.1786 - acc: 0.9557\n",
      "Epoch 00011: val_acc did not improve from 0.95278\n",
      "13910/13910 [==============================] - 92s 7ms/sample - loss: 0.1786 - acc: 0.9557 - val_loss: 0.2813 - val_acc: 0.9211\n",
      "Epoch 12/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.1607 - acc: 0.9623\n",
      "Epoch 00012: val_acc did not improve from 0.95278\n",
      "13910/13910 [==============================] - 94s 7ms/sample - loss: 0.1607 - acc: 0.9623 - val_loss: 0.3715 - val_acc: 0.8972\n",
      "Epoch 13/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.1372 - acc: 0.9710\n",
      "Epoch 00013: val_acc did not improve from 0.95278\n",
      "13910/13910 [==============================] - 93s 7ms/sample - loss: 0.1372 - acc: 0.9710 - val_loss: 0.3441 - val_acc: 0.9023\n",
      "Epoch 14/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.1440 - acc: 0.9659\n",
      "Epoch 00014: val_acc improved from 0.95278 to 0.96766, saving model to CNN-weights-improvement-14-0.97.hdf5\n",
      "13910/13910 [==============================] - 95s 7ms/sample - loss: 0.1440 - acc: 0.9659 - val_loss: 0.1611 - val_acc: 0.9677\n",
      "Epoch 15/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.1525 - acc: 0.9625\n",
      "Epoch 00015: val_acc did not improve from 0.96766\n",
      "13910/13910 [==============================] - 111s 8ms/sample - loss: 0.1525 - acc: 0.9625 - val_loss: 0.4239 - val_acc: 0.8622\n",
      "Epoch 16/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.1112 - acc: 0.9774\n",
      "Epoch 00016: val_acc did not improve from 0.96766\n",
      "13910/13910 [==============================] - 94s 7ms/sample - loss: 0.1112 - acc: 0.9774 - val_loss: 0.1622 - val_acc: 0.9618\n",
      "Epoch 17/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0968 - acc: 0.9805\n",
      "Epoch 00017: val_acc did not improve from 0.96766\n",
      "13910/13910 [==============================] - 97s 7ms/sample - loss: 0.0968 - acc: 0.9805 - val_loss: 0.1587 - val_acc: 0.9670\n",
      "Epoch 18/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.1010 - acc: 0.9774\n",
      "Epoch 00018: val_acc did not improve from 0.96766\n",
      "13910/13910 [==============================] - 113s 8ms/sample - loss: 0.1010 - acc: 0.9774 - val_loss: 0.4298 - val_acc: 0.8571\n",
      "Epoch 19/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.1036 - acc: 0.9804\n",
      "Epoch 00019: val_acc did not improve from 0.96766\n",
      "13910/13910 [==============================] - 127s 9ms/sample - loss: 0.1036 - acc: 0.9804 - val_loss: 0.5062 - val_acc: 0.8571\n",
      "Epoch 20/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0864 - acc: 0.9827\n",
      "Epoch 00020: val_acc did not improve from 0.96766\n",
      "13910/13910 [==============================] - 129s 9ms/sample - loss: 0.0864 - acc: 0.9827 - val_loss: 0.2025 - val_acc: 0.9547\n",
      "Epoch 21/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.1150 - acc: 0.9738\n",
      "Epoch 00021: val_acc did not improve from 0.96766\n",
      "13910/13910 [==============================] - 131s 9ms/sample - loss: 0.1150 - acc: 0.9738 - val_loss: 0.2458 - val_acc: 0.9360\n",
      "Epoch 22/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0790 - acc: 0.9866\n",
      "Epoch 00022: val_acc did not improve from 0.96766\n",
      "13910/13910 [==============================] - 129s 9ms/sample - loss: 0.0790 - acc: 0.9866 - val_loss: 0.3274 - val_acc: 0.9224\n",
      "Epoch 23/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0807 - acc: 0.9830\n",
      "Epoch 00023: val_acc did not improve from 0.96766\n",
      "13910/13910 [==============================] - 126s 9ms/sample - loss: 0.0807 - acc: 0.9830 - val_loss: 0.2380 - val_acc: 0.9334\n",
      "Epoch 24/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0914 - acc: 0.9816\n",
      "Epoch 00024: val_acc improved from 0.96766 to 0.97736, saving model to CNN-weights-improvement-24-0.98.hdf5\n",
      "13910/13910 [==============================] - 130s 9ms/sample - loss: 0.0914 - acc: 0.9816 - val_loss: 0.1312 - val_acc: 0.9774\n",
      "Epoch 25/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0800 - acc: 0.9820\n",
      "Epoch 00025: val_acc did not improve from 0.97736\n",
      "13910/13910 [==============================] - 125s 9ms/sample - loss: 0.0800 - acc: 0.9820 - val_loss: 0.1580 - val_acc: 0.9644\n",
      "Epoch 26/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0648 - acc: 0.9883\n",
      "Epoch 00026: val_acc did not improve from 0.97736\n",
      "13910/13910 [==============================] - 129s 9ms/sample - loss: 0.0648 - acc: 0.9883 - val_loss: 0.1361 - val_acc: 0.9683\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0599 - acc: 0.9917\n",
      "Epoch 00027: val_acc did not improve from 0.97736\n",
      "13910/13910 [==============================] - 124s 9ms/sample - loss: 0.0599 - acc: 0.9917 - val_loss: 0.2144 - val_acc: 0.9521\n",
      "Epoch 28/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0730 - acc: 0.9851\n",
      "Epoch 00028: val_acc did not improve from 0.97736\n",
      "13910/13910 [==============================] - 129s 9ms/sample - loss: 0.0730 - acc: 0.9851 - val_loss: 0.2468 - val_acc: 0.9502\n",
      "Epoch 29/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0660 - acc: 0.9878\n",
      "Epoch 00029: val_acc did not improve from 0.97736\n",
      "13910/13910 [==============================] - 134s 10ms/sample - loss: 0.0660 - acc: 0.9878 - val_loss: 0.1851 - val_acc: 0.9573\n",
      "Epoch 30/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0711 - acc: 0.9849\n",
      "Epoch 00030: val_acc did not improve from 0.97736\n",
      "13910/13910 [==============================] - 141s 10ms/sample - loss: 0.0711 - acc: 0.9849 - val_loss: 0.2944 - val_acc: 0.9301\n",
      "Epoch 31/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0684 - acc: 0.9876\n",
      "Epoch 00031: val_acc did not improve from 0.97736\n",
      "13910/13910 [==============================] - 140s 10ms/sample - loss: 0.0684 - acc: 0.9876 - val_loss: 0.3396 - val_acc: 0.8965\n",
      "Epoch 32/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0635 - acc: 0.9895\n",
      "Epoch 00032: val_acc did not improve from 0.97736\n",
      "13910/13910 [==============================] - 143s 10ms/sample - loss: 0.0635 - acc: 0.9895 - val_loss: 0.1341 - val_acc: 0.9715\n",
      "Epoch 33/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0517 - acc: 0.9918\n",
      "Epoch 00033: val_acc did not improve from 0.97736\n",
      "13910/13910 [==============================] - 140s 10ms/sample - loss: 0.0517 - acc: 0.9918 - val_loss: 0.1510 - val_acc: 0.9767\n",
      "Epoch 34/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0590 - acc: 0.9889\n",
      "Epoch 00034: val_acc did not improve from 0.97736\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "13910/13910 [==============================] - 123s 9ms/sample - loss: 0.0590 - acc: 0.9889 - val_loss: 0.1288 - val_acc: 0.9754\n",
      "Epoch 35/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0261 - acc: 0.9992\n",
      "Epoch 00035: val_acc improved from 0.97736 to 0.97801, saving model to CNN-weights-improvement-35-0.98.hdf5\n",
      "13910/13910 [==============================] - 124s 9ms/sample - loss: 0.0261 - acc: 0.9992 - val_loss: 0.1205 - val_acc: 0.9780\n",
      "Epoch 36/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0228 - acc: 0.9996\n",
      "Epoch 00036: val_acc did not improve from 0.97801\n",
      "13910/13910 [==============================] - 127s 9ms/sample - loss: 0.0228 - acc: 0.9996 - val_loss: 0.1404 - val_acc: 0.9722\n",
      "Epoch 37/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0213 - acc: 0.9997\n",
      "Epoch 00037: val_acc improved from 0.97801 to 0.97995, saving model to CNN-weights-improvement-37-0.98.hdf5\n",
      "13910/13910 [==============================] - 135s 10ms/sample - loss: 0.0213 - acc: 0.9997 - val_loss: 0.1280 - val_acc: 0.9799\n",
      "Epoch 38/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0198 - acc: 0.9996\n",
      "Epoch 00038: val_acc did not improve from 0.97995\n",
      "13910/13910 [==============================] - 140s 10ms/sample - loss: 0.0198 - acc: 0.9996 - val_loss: 0.1652 - val_acc: 0.9735\n",
      "Epoch 39/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0189 - acc: 0.9997\n",
      "Epoch 00039: val_acc did not improve from 0.97995\n",
      "13910/13910 [==============================] - 137s 10ms/sample - loss: 0.0189 - acc: 0.9997 - val_loss: 0.1308 - val_acc: 0.9799\n",
      "Epoch 40/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0185 - acc: 0.9994\n",
      "Epoch 00040: val_acc improved from 0.97995 to 0.98060, saving model to CNN-weights-improvement-40-0.98.hdf5\n",
      "13910/13910 [==============================] - 142s 10ms/sample - loss: 0.0185 - acc: 0.9994 - val_loss: 0.1188 - val_acc: 0.9806\n",
      "Epoch 41/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0178 - acc: 0.9996\n",
      "Epoch 00041: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 142s 10ms/sample - loss: 0.0178 - acc: 0.9996 - val_loss: 0.1497 - val_acc: 0.9728\n",
      "Epoch 42/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0177 - acc: 0.9996\n",
      "Epoch 00042: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 134s 10ms/sample - loss: 0.0177 - acc: 0.9996 - val_loss: 0.1233 - val_acc: 0.9793\n",
      "Epoch 43/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0168 - acc: 0.9997\n",
      "Epoch 00043: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 125s 9ms/sample - loss: 0.0168 - acc: 0.9997 - val_loss: 0.1374 - val_acc: 0.9793\n",
      "Epoch 44/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0171 - acc: 0.9996\n",
      "Epoch 00044: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 104s 8ms/sample - loss: 0.0171 - acc: 0.9996 - val_loss: 0.1295 - val_acc: 0.9780\n",
      "Epoch 45/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0165 - acc: 0.9995\n",
      "Epoch 00045: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 103s 7ms/sample - loss: 0.0165 - acc: 0.9995 - val_loss: 0.1276 - val_acc: 0.9793\n",
      "Epoch 46/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0165 - acc: 0.9995\n",
      "Epoch 00046: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 104s 7ms/sample - loss: 0.0165 - acc: 0.9995 - val_loss: 0.1263 - val_acc: 0.9793\n",
      "Epoch 47/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0155 - acc: 0.9998\n",
      "Epoch 00047: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 103s 7ms/sample - loss: 0.0155 - acc: 0.9998 - val_loss: 0.1559 - val_acc: 0.9709\n",
      "Epoch 48/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0164 - acc: 0.9996\n",
      "Epoch 00048: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 99s 7ms/sample - loss: 0.0164 - acc: 0.9996 - val_loss: 0.1394 - val_acc: 0.9748\n",
      "Epoch 49/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0158 - acc: 0.9997\n",
      "Epoch 00049: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 100s 7ms/sample - loss: 0.0158 - acc: 0.9997 - val_loss: 0.1520 - val_acc: 0.9754\n",
      "Epoch 50/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0156 - acc: 0.9996\n",
      "Epoch 00050: val_acc did not improve from 0.98060\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "13910/13910 [==============================] - 102s 7ms/sample - loss: 0.0156 - acc: 0.9996 - val_loss: 0.1255 - val_acc: 0.9806\n",
      "Epoch 51/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0142 - acc: 0.9999\n",
      "Epoch 00051: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 94s 7ms/sample - loss: 0.0142 - acc: 0.9999 - val_loss: 0.1342 - val_acc: 0.9799\n",
      "Epoch 52/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0139 - acc: 1.0000\n",
      "Epoch 00052: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 109s 8ms/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.1334 - val_acc: 0.9806\n",
      "Epoch 53/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0138 - acc: 0.9999\n",
      "Epoch 00053: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 129s 9ms/sample - loss: 0.0138 - acc: 0.9999 - val_loss: 0.1320 - val_acc: 0.9780\n",
      "Epoch 54/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0136 - acc: 0.9999\n",
      "Epoch 00054: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 125s 9ms/sample - loss: 0.0136 - acc: 0.9999 - val_loss: 0.1352 - val_acc: 0.9799\n",
      "Epoch 55/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0134 - acc: 1.0000\n",
      "Epoch 00055: val_acc did not improve from 0.98060\n",
      "13910/13910 [==============================] - 137s 10ms/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.1331 - val_acc: 0.9774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200\n",
      "13910/13910 [==============================] - ETA: 0s - loss: 0.0133 - acc: 0.9999"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "#model2.load_weights(\"M2-weights-improvement-23-0.70.hdf5\")\n",
    "history=model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.1,\n",
    "          validation_data=None,\n",
    "          shuffle=True,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########画图\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "acc = history.history['acc']     #获取训练集准确性数据\n",
    "val_acc = history.history['val_acc']    #获取验证集准确性数据\n",
    "loss = history.history['loss']          #获取训练集错误值数据\n",
    "val_loss = history.history['val_loss']  #获取验证集错误值数据\n",
    "font = {\n",
    "    'family' : 'Bitstream Vera Sans',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "width = 12\n",
    "height = 8\n",
    "plt.figure(figsize=(width, height))\n",
    "epochs = range(1,len(acc)+1)\n",
    "plt.plot(epochs,acc,'r',label='Trainning acc',linewidth=2)     #以epochs为横坐标，以训练集准确性为纵坐标\n",
    "plt.plot(epochs,val_acc,'b--',label='Vaildation acc',linewidth=2) #以epochs为横坐标，以验证集准确性为纵坐标\n",
    "plt.legend(loc='best', shadow=True)   #绘制图例，即标明图中的线段代表何种含义\n",
    "plt.title(\"Training session's progress over epochs\")\n",
    "plt.ylabel('Training Progress (Accuracy values)')\n",
    "plt.xlabel('Training epochs')\n",
    "\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.plot(epochs,loss,'r',label='Trainning loss',linewidth=2)\n",
    "plt.plot(epochs,val_loss,'b--',label='Vaildation loss',linewidth=2)\n",
    "plt.legend(loc='best', shadow=True)   #绘制图例，即标明图中的线段代表何种含义\n",
    "plt.title(\"Training session's progress over epochs\")\n",
    "plt.ylabel('Training Progress (Loss values)')\n",
    "plt.xlabel('Training epochs') \n",
    "plt.show()    #显示所有图表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.load_weights(\"M2-weights-improvement-45-0.97.hdf5\")\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# confusion matrix\n",
    "Y_pred=model.predict_classes(X_test)\n",
    "print(Y_pred.shape)\n",
    "# Y_pred=np.transpose([Y_pred])\n",
    "# print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_cmap=plt.cm.Greens\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "\n",
    "\n",
    "print('| Confusion Matrix |')\n",
    "print('--------------------')\n",
    "print('\\n {}'.format(cm))\n",
    "class_labels=['Pre','Mid','Post']\n",
    "# plot confusin matrix\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.grid(b=False)\n",
    "plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n",
    "plt.show()\n",
    "class_labels=[0,1,2]\n",
    "# get classification report\n",
    "print('| Classifiction Report |')\n",
    "print('-------------------------')\n",
    "classification_report = metrics.classification_report(Y_test,Y_pred,labels =class_labels)\n",
    "# store report in results\n",
    "\n",
    "\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
