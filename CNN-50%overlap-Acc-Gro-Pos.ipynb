{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Fatiuge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1  as tf\n",
    "import numpy as np\n",
    "import os,sys\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import scipy.io as scio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17174, 200, 9)\n",
      "(17174, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_mat = scio.loadmat('X_train-3Classes-50%overlap.mat')\n",
    "key_name = list(X_train_mat.keys())[-1]\n",
    "X_train=X_train_mat[key_name]\n",
    "print(X_train.shape)\n",
    "\n",
    "Y_train_mat = scio.loadmat('Y_train-3Classes-50%overlap.mat')\n",
    "key_name = list(Y_train_mat.keys())[-1]\n",
    "Y_train=Y_train_mat[key_name]\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17174, 200, 9)\n",
      "(17174, 1)\n"
     ]
    }
   ],
   "source": [
    "#只取前列数据\n",
    "X_train=X_train[:,:,0:9]#只取前\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15456, 200, 9)\n",
      "(15456, 1)\n",
      "(1718, 200, 9)\n",
      "(1718, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 0)\n",
    "#X_test, X_valid, Y_test, Y_valid = train_test_split(X_test, Y_test, test_size = 0.5, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(-1,200,9,1)\n",
    "X_test=X_test.reshape(-1,200,9,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(42)\n",
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Flatten, Reshape, Softmax\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, TimeDistributed,LSTM,Bidirectional,BatchNormalization\n",
    "#from keras import backend as K\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from attention import Attention\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# callbacks:\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 9 15456\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Initializing parameters\n",
    "epochs = 200\n",
    "batch_size = 256\n",
    "timesteps = 200\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "#input_shape = (timesteps, input_dim)\n",
    "\n",
    "print(timesteps,input_dim,len(X_train))\n",
    "print(n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 100, 9, 32)        608       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 50, 9, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 9, 64)         18496     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 9, 128)        24704     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 25, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 4, 128)        98432     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 38403     \n",
      "=================================================================\n",
      "Total params: 180,643\n",
      "Trainable params: 180,643\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "input_shape = (256, 200, 9, 1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(18,1),activation='relu',strides=(2,1),padding='SAME',input_shape=(200,9,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Conv2D(64, (9, 1), activation='relu',padding='SAME'))\n",
    "model.add(Conv2D(128, (3, 1), activation='relu',padding='SAME'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "model.add(Conv2D(128, (1, 6), activation='relu', padding='VALID'))\n",
    "model.add(Flatten())\n",
    "\n",
    "# Adding a dense output layer with sigmoid activation\n",
    "model.add(Dense(n_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01)))\n",
    "\n",
    "model.summary()\n",
    "#-------------------\n",
    "# Compiling the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])#二分类：optimizer='adam', loss='binary_crossentropy'；多分类时激活函数改为softmax。损失函数改为：loss=‘categorical_crossentropy’\n",
    "\n",
    "filepath=\"CNN-weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "mc = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',  # log 目录\n",
    "                 histogram_freq=1,  # 按照何等频率（epoch）来计算直方图，0为不计算\n",
    "                 batch_size=64,     # 用多大量的数据计算直方图\n",
    "                 write_graph=True,  # 是否存储网络结构图\n",
    "                 write_grads=True, # 是否可视化梯度直方图\n",
    "                 write_images=True,# 是否可视化参数\n",
    "                 embeddings_freq=0,\n",
    "                 embeddings_layer_names=None,\n",
    "                 embeddings_metadata=None)\n",
    "\n",
    "es=EarlyStopping(monitor='val_loss', patience=16, verbose=2)\n",
    "rp=ReduceLROnPlateau(\n",
    "    monitor='val_acc',\n",
    "    factor=0.25,\n",
    "    patience=10,#\n",
    "    verbose=2,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0\n",
    ")\n",
    "\n",
    "# callbacks_list = [mc,tb,es,rp]\n",
    "callbacks_list =[mc,es,rp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13910 samples, validate on 1546 samples\n",
      "Epoch 1/200\n",
      " 3072/13910 [=====>........................] - ETA: 55s - loss: 8.7596 - acc: 0.2878"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "#model2.load_weights(\"M2-weights-improvement-23-0.70.hdf5\")\n",
    "history=model.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.1,\n",
    "          validation_data=None,\n",
    "          shuffle=True,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########画图\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "acc = history.history['acc']     #获取训练集准确性数据\n",
    "val_acc = history.history['val_acc']    #获取验证集准确性数据\n",
    "loss = history.history['loss']          #获取训练集错误值数据\n",
    "val_loss = history.history['val_loss']  #获取验证集错误值数据\n",
    "font = {\n",
    "    'family' : 'Bitstream Vera Sans',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "width = 12\n",
    "height = 8\n",
    "plt.figure(figsize=(width, height))\n",
    "epochs = range(1,len(acc)+1)\n",
    "plt.plot(epochs,acc,'r',label='Trainning acc',linewidth=2)     #以epochs为横坐标，以训练集准确性为纵坐标\n",
    "plt.plot(epochs,val_acc,'b--',label='Vaildation acc',linewidth=2) #以epochs为横坐标，以验证集准确性为纵坐标\n",
    "plt.legend(loc='best', shadow=True)   #绘制图例，即标明图中的线段代表何种含义\n",
    "plt.title(\"Training session's progress over epochs\")\n",
    "plt.ylabel('Training Progress (Accuracy values)')\n",
    "plt.xlabel('Training epochs')\n",
    "\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.plot(epochs,loss,'r',label='Trainning loss',linewidth=2)\n",
    "plt.plot(epochs,val_loss,'b--',label='Vaildation loss',linewidth=2)\n",
    "plt.legend(loc='best', shadow=True)   #绘制图例，即标明图中的线段代表何种含义\n",
    "plt.title(\"Training session's progress over epochs\")\n",
    "plt.ylabel('Training Progress (Loss values)')\n",
    "plt.xlabel('Training epochs') \n",
    "plt.show()    #显示所有图表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.load_weights(\"M2-weights-improvement-45-0.97.hdf5\")\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# confusion matrix\n",
    "Y_pred=model.predict_classes(X_test)\n",
    "print(Y_pred.shape)\n",
    "# Y_pred=np.transpose([Y_pred])\n",
    "# print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_cmap=plt.cm.Greens\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "\n",
    "\n",
    "print('| Confusion Matrix |')\n",
    "print('--------------------')\n",
    "print('\\n {}'.format(cm))\n",
    "class_labels=['Pre','Mid','Post']\n",
    "# plot confusin matrix\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.grid(b=False)\n",
    "plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n",
    "plt.show()\n",
    "class_labels=[0,1,2]\n",
    "# get classification report\n",
    "print('| Classifiction Report |')\n",
    "print('-------------------------')\n",
    "classification_report = metrics.classification_report(Y_test,Y_pred,labels =class_labels)\n",
    "# store report in results\n",
    "\n",
    "\n",
    "print(classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
