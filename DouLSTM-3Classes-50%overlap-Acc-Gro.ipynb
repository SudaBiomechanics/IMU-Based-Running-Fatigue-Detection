{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1  as tf\n",
    "import numpy as np\n",
    "import os,sys\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import scipy.io as scio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34334, 200, 9)\n",
      "(34334, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_mat = scio.loadmat('X_train-3Classes-50%overlap.mat')\n",
    "key_name = list(X_train_mat.keys())[-1]\n",
    "X_train=X_train_mat[key_name]\n",
    "print(X_train.shape)\n",
    "\n",
    "Y_train_mat = scio.loadmat('Y_train-3Classes-50%overlap.mat')\n",
    "key_name = list(Y_train_mat.keys())[-1]\n",
    "Y_train=Y_train_mat[key_name]\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34334, 200, 6)\n",
      "(34334, 1)\n"
     ]
    }
   ],
   "source": [
    "#只取前六列Acc数据\n",
    "X_train=X_train[:,:,0:6]##只取前六列Acc数据\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30900, 200, 6)\n",
      "(30900, 1)\n",
      "(3434, 200, 6)\n",
      "(3434, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train, test_size = 0.1, random_state = 0)\n",
    "#X_test, X_valid, Y_test, Y_valid = train_test_split(X_test, Y_test, test_size = 0.5, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(42)\n",
    "# Configuring a session\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout,Flatten, Reshape, Softmax\n",
    "from keras.layers import Conv2D, MaxPooling2D, Conv1D, MaxPooling1D, TimeDistributed,LSTM,Bidirectional,BatchNormalization\n",
    "#from keras import backend as K\n",
    "from tensorflow.compat.v1.keras import backend as K\n",
    "from attention import Attention\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)\n",
    "\n",
    "# callbacks:\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to count the number of classes\n",
    "def _count_classes(y):\n",
    "    return len(set([tuple(category) for category in y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters\n",
    "epochs = 200\n",
    "batch_size = 256\n",
    "timesteps = 200\n",
    "input_dim = len(X_train[0][0])\n",
    "n_classes = _count_classes(Y_train)\n",
    "#input_shape = (timesteps, input_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 200, 128)          69120     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 118,723\n",
      "Trainable params: 118,723\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initiliazing the sequential model\n",
    "model2 = Sequential()\n",
    "# Configuring the parameters\n",
    "model2.add(LSTM(128, return_sequences=True, input_shape=(timesteps, input_dim), kernel_initializer='glorot_normal'))\n",
    "# Adding a dropout layer\n",
    "model2.add(Dropout(0.5))\n",
    "#model2.add(Attention(64))\n",
    "# #model2.add(BatchNormalization())\n",
    "model2.add(LSTM(64))\n",
    "# # Adding a dropout layer\n",
    "model2.add(Dropout(0.5))\n",
    "# # Adding a dense output layer with sigmoid activation\n",
    "model2.add(Dense(n_classes, activation='softmax',kernel_regularizer=regularizers.l2(0.01),\n",
    "                activity_regularizer=regularizers.l1(0.01)))\n",
    "\n",
    "model2.summary()\n",
    "#-------------------\n",
    "# Compiling the model\n",
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])#\n",
    "\n",
    "filepath=\"M2-weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "\n",
    "mc = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "tb = TensorBoard(log_dir='./logs',  # log 目录\n",
    "                 histogram_freq=1,  # 按照何等频率（epoch）来计算直方图，0为不计算\n",
    "                 batch_size=64,     # 用多大量的数据计算直方图\n",
    "                 write_graph=True,  # 是否存储网络结构图\n",
    "                 write_grads=True, # 是否可视化梯度直方图\n",
    "                 write_images=True,# 是否可视化参数\n",
    "                 embeddings_freq=0,\n",
    "                 embeddings_layer_names=None,\n",
    "                 embeddings_metadata=None)\n",
    "\n",
    "es=EarlyStopping(monitor='val_loss', patience=14, verbose=2)\n",
    "rp=ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.25,\n",
    "    patience=8,#\n",
    "    verbose=2,\n",
    "    mode='auto',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=0,\n",
    "    min_lr=0\n",
    ")\n",
    "\n",
    "# callbacks_list = [mc,tb,es,rp]\n",
    "callbacks_list =[mc,es,rp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27810 samples, validate on 3090 samples\n",
      "Epoch 1/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 1.1047 - acc: 0.4209WARNING:tensorflow:From D:\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.48350, saving model to M2-weights-improvement-01-0.48.hdf5\n",
      "27810/27810 [==============================] - 214s 8ms/sample - loss: 1.1047 - acc: 0.4209 - val_loss: 1.0322 - val_acc: 0.4835\n",
      "Epoch 2/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.9961 - acc: 0.4905\n",
      "Epoch 00002: val_acc improved from 0.48350 to 0.50777, saving model to M2-weights-improvement-02-0.51.hdf5\n",
      "27810/27810 [==============================] - 223s 8ms/sample - loss: 0.9961 - acc: 0.4905 - val_loss: 0.9558 - val_acc: 0.5078\n",
      "Epoch 3/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.9166 - acc: 0.5441\n",
      "Epoch 00003: val_acc improved from 0.50777 to 0.59806, saving model to M2-weights-improvement-03-0.60.hdf5\n",
      "27810/27810 [==============================] - 219s 8ms/sample - loss: 0.9166 - acc: 0.5441 - val_loss: 0.8269 - val_acc: 0.5981\n",
      "Epoch 4/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.8497 - acc: 0.5870\n",
      "Epoch 00004: val_acc improved from 0.59806 to 0.62751, saving model to M2-weights-improvement-04-0.63.hdf5\n",
      "27810/27810 [==============================] - 219s 8ms/sample - loss: 0.8497 - acc: 0.5870 - val_loss: 0.8041 - val_acc: 0.6275\n",
      "Epoch 5/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.7860 - acc: 0.6442\n",
      "Epoch 00005: val_acc improved from 0.62751 to 0.69320, saving model to M2-weights-improvement-05-0.69.hdf5\n",
      "27810/27810 [==============================] - 226s 8ms/sample - loss: 0.7860 - acc: 0.6442 - val_loss: 0.7062 - val_acc: 0.6932\n",
      "Epoch 6/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.7299 - acc: 0.6839\n",
      "Epoch 00006: val_acc improved from 0.69320 to 0.72298, saving model to M2-weights-improvement-06-0.72.hdf5\n",
      "27810/27810 [==============================] - 214s 8ms/sample - loss: 0.7299 - acc: 0.6839 - val_loss: 0.6687 - val_acc: 0.7230\n",
      "Epoch 7/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.6881 - acc: 0.7108\n",
      "Epoch 00007: val_acc improved from 0.72298 to 0.77055, saving model to M2-weights-improvement-07-0.77.hdf5\n",
      "27810/27810 [==============================] - 213s 8ms/sample - loss: 0.6881 - acc: 0.7108 - val_loss: 0.5926 - val_acc: 0.7706\n",
      "Epoch 8/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.6354 - acc: 0.7406\n",
      "Epoch 00008: val_acc improved from 0.77055 to 0.77346, saving model to M2-weights-improvement-08-0.77.hdf5\n",
      "27810/27810 [==============================] - 213s 8ms/sample - loss: 0.6354 - acc: 0.7406 - val_loss: 0.5667 - val_acc: 0.7735\n",
      "Epoch 9/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.5895 - acc: 0.7677\n",
      "Epoch 00009: val_acc improved from 0.77346 to 0.80777, saving model to M2-weights-improvement-09-0.81.hdf5\n",
      "27810/27810 [==============================] - 222s 8ms/sample - loss: 0.5895 - acc: 0.7677 - val_loss: 0.5092 - val_acc: 0.8078\n",
      "Epoch 10/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.5396 - acc: 0.7910\n",
      "Epoch 00010: val_acc did not improve from 0.80777\n",
      "27810/27810 [==============================] - 220s 8ms/sample - loss: 0.5396 - acc: 0.7910 - val_loss: 0.5040 - val_acc: 0.8006\n",
      "Epoch 11/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.5026 - acc: 0.8077\n",
      "Epoch 00011: val_acc improved from 0.80777 to 0.82330, saving model to M2-weights-improvement-11-0.82.hdf5\n",
      "27810/27810 [==============================] - 216s 8ms/sample - loss: 0.5026 - acc: 0.8077 - val_loss: 0.4790 - val_acc: 0.8233\n",
      "Epoch 12/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.4775 - acc: 0.8222\n",
      "Epoch 00012: val_acc did not improve from 0.82330\n",
      "27810/27810 [==============================] - 215s 8ms/sample - loss: 0.4775 - acc: 0.8222 - val_loss: 0.5500 - val_acc: 0.7832\n",
      "Epoch 13/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.4445 - acc: 0.8341\n",
      "Epoch 00013: val_acc improved from 0.82330 to 0.84595, saving model to M2-weights-improvement-13-0.85.hdf5\n",
      "27810/27810 [==============================] - 225s 8ms/sample - loss: 0.4445 - acc: 0.8341 - val_loss: 0.4263 - val_acc: 0.8460\n",
      "Epoch 14/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.4147 - acc: 0.8474\n",
      "Epoch 00014: val_acc improved from 0.84595 to 0.86149, saving model to M2-weights-improvement-14-0.86.hdf5\n",
      "27810/27810 [==============================] - 213s 8ms/sample - loss: 0.4147 - acc: 0.8474 - val_loss: 0.3865 - val_acc: 0.8615\n",
      "Epoch 15/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.3895 - acc: 0.8578\n",
      "Epoch 00015: val_acc improved from 0.86149 to 0.86278, saving model to M2-weights-improvement-15-0.86.hdf5\n",
      "27810/27810 [==============================] - 214s 8ms/sample - loss: 0.3895 - acc: 0.8578 - val_loss: 0.3937 - val_acc: 0.8628\n",
      "Epoch 16/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.3609 - acc: 0.8732\n",
      "Epoch 00016: val_acc did not improve from 0.86278\n",
      "27810/27810 [==============================] - 213s 8ms/sample - loss: 0.3609 - acc: 0.8732 - val_loss: 0.4680 - val_acc: 0.8217\n",
      "Epoch 17/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.3449 - acc: 0.8800\n",
      "Epoch 00017: val_acc did not improve from 0.86278\n",
      "27810/27810 [==============================] - 218s 8ms/sample - loss: 0.3449 - acc: 0.8800 - val_loss: 0.6205 - val_acc: 0.7838\n",
      "Epoch 18/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.3311 - acc: 0.8849\n",
      "Epoch 00018: val_acc improved from 0.86278 to 0.88285, saving model to M2-weights-improvement-18-0.88.hdf5\n",
      "27810/27810 [==============================] - 221s 8ms/sample - loss: 0.3311 - acc: 0.8849 - val_loss: 0.3296 - val_acc: 0.8828\n",
      "Epoch 19/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.3089 - acc: 0.8970\n",
      "Epoch 00019: val_acc did not improve from 0.88285\n",
      "27810/27810 [==============================] - 234s 8ms/sample - loss: 0.3089 - acc: 0.8970 - val_loss: 0.3629 - val_acc: 0.8706\n",
      "Epoch 20/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.2871 - acc: 0.9029\n",
      "Epoch 00020: val_acc did not improve from 0.88285\n",
      "27810/27810 [==============================] - 235s 8ms/sample - loss: 0.2871 - acc: 0.9029 - val_loss: 0.3988 - val_acc: 0.8706\n",
      "Epoch 21/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.2791 - acc: 0.9083\n",
      "Epoch 00021: val_acc improved from 0.88285 to 0.89838, saving model to M2-weights-improvement-21-0.90.hdf5\n",
      "27810/27810 [==============================] - 243s 9ms/sample - loss: 0.2791 - acc: 0.9083 - val_loss: 0.3000 - val_acc: 0.8984\n",
      "Epoch 22/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.2579 - acc: 0.9157\n",
      "Epoch 00022: val_acc did not improve from 0.89838\n",
      "27810/27810 [==============================] - 232s 8ms/sample - loss: 0.2579 - acc: 0.9157 - val_loss: 0.3111 - val_acc: 0.8922\n",
      "Epoch 23/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.2506 - acc: 0.9214\n",
      "Epoch 00023: val_acc improved from 0.89838 to 0.90259, saving model to M2-weights-improvement-23-0.90.hdf5\n",
      "27810/27810 [==============================] - 229s 8ms/sample - loss: 0.2506 - acc: 0.9214 - val_loss: 0.3092 - val_acc: 0.9026\n",
      "Epoch 24/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.2315 - acc: 0.9289\n",
      "Epoch 00024: val_acc improved from 0.90259 to 0.90615, saving model to M2-weights-improvement-24-0.91.hdf5\n",
      "27810/27810 [==============================] - 230s 8ms/sample - loss: 0.2315 - acc: 0.9289 - val_loss: 0.2865 - val_acc: 0.9061\n",
      "Epoch 25/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.2222 - acc: 0.9311\n",
      "Epoch 00025: val_acc improved from 0.90615 to 0.90971, saving model to M2-weights-improvement-25-0.91.hdf5\n",
      "27810/27810 [==============================] - 228s 8ms/sample - loss: 0.2222 - acc: 0.9311 - val_loss: 0.2849 - val_acc: 0.9097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.2069 - acc: 0.9369\n",
      "Epoch 00026: val_acc improved from 0.90971 to 0.91165, saving model to M2-weights-improvement-26-0.91.hdf5\n",
      "27810/27810 [==============================] - 229s 8ms/sample - loss: 0.2069 - acc: 0.9369 - val_loss: 0.2772 - val_acc: 0.9117\n",
      "Epoch 27/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1995 - acc: 0.9406\n",
      "Epoch 00027: val_acc improved from 0.91165 to 0.91553, saving model to M2-weights-improvement-27-0.92.hdf5\n",
      "27810/27810 [==============================] - 234s 8ms/sample - loss: 0.1995 - acc: 0.9406 - val_loss: 0.2662 - val_acc: 0.9155\n",
      "Epoch 28/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1875 - acc: 0.9442\n",
      "Epoch 00028: val_acc did not improve from 0.91553\n",
      "27810/27810 [==============================] - 235s 8ms/sample - loss: 0.1875 - acc: 0.9442 - val_loss: 0.2790 - val_acc: 0.9097\n",
      "Epoch 29/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1830 - acc: 0.9467\n",
      "Epoch 00029: val_acc did not improve from 0.91553\n",
      "27810/27810 [==============================] - 236s 8ms/sample - loss: 0.1830 - acc: 0.9467 - val_loss: 0.3135 - val_acc: 0.9032\n",
      "Epoch 30/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1718 - acc: 0.9506\n",
      "Epoch 00030: val_acc did not improve from 0.91553\n",
      "27810/27810 [==============================] - 240s 9ms/sample - loss: 0.1718 - acc: 0.9506 - val_loss: 0.2932 - val_acc: 0.9139\n",
      "Epoch 31/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1668 - acc: 0.9529\n",
      "Epoch 00031: val_acc improved from 0.91553 to 0.92168, saving model to M2-weights-improvement-31-0.92.hdf5\n",
      "27810/27810 [==============================] - 231s 8ms/sample - loss: 0.1668 - acc: 0.9529 - val_loss: 0.2633 - val_acc: 0.9217\n",
      "Epoch 32/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1582 - acc: 0.9567\n",
      "Epoch 00032: val_acc improved from 0.92168 to 0.92621, saving model to M2-weights-improvement-32-0.93.hdf5\n",
      "27810/27810 [==============================] - 224s 8ms/sample - loss: 0.1582 - acc: 0.9567 - val_loss: 0.2542 - val_acc: 0.9262\n",
      "Epoch 33/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1500 - acc: 0.9585\n",
      "Epoch 00033: val_acc did not improve from 0.92621\n",
      "27810/27810 [==============================] - 224s 8ms/sample - loss: 0.1500 - acc: 0.9585 - val_loss: 0.3297 - val_acc: 0.9039\n",
      "Epoch 34/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1469 - acc: 0.9611\n",
      "Epoch 00034: val_acc improved from 0.92621 to 0.93398, saving model to M2-weights-improvement-34-0.93.hdf5\n",
      "27810/27810 [==============================] - 224s 8ms/sample - loss: 0.1469 - acc: 0.9611 - val_loss: 0.2442 - val_acc: 0.9340\n",
      "Epoch 35/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1456 - acc: 0.9613\n",
      "Epoch 00035: val_acc did not improve from 0.93398\n",
      "27810/27810 [==============================] - 225s 8ms/sample - loss: 0.1456 - acc: 0.9613 - val_loss: 0.3783 - val_acc: 0.8913\n",
      "Epoch 36/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1384 - acc: 0.9637\n",
      "Epoch 00036: val_acc did not improve from 0.93398\n",
      "27810/27810 [==============================] - 230s 8ms/sample - loss: 0.1384 - acc: 0.9637 - val_loss: 0.2502 - val_acc: 0.9285\n",
      "Epoch 37/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1364 - acc: 0.9647\n",
      "Epoch 00037: val_acc did not improve from 0.93398\n",
      "27810/27810 [==============================] - 227s 8ms/sample - loss: 0.1364 - acc: 0.9647 - val_loss: 0.2687 - val_acc: 0.9259\n",
      "Epoch 38/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1322 - acc: 0.9663\n",
      "Epoch 00038: val_acc did not improve from 0.93398\n",
      "27810/27810 [==============================] - 231s 8ms/sample - loss: 0.1322 - acc: 0.9663 - val_loss: 0.2548 - val_acc: 0.9307\n",
      "Epoch 39/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1306 - acc: 0.9661\n",
      "Epoch 00039: val_acc did not improve from 0.93398\n",
      "27810/27810 [==============================] - 229s 8ms/sample - loss: 0.1306 - acc: 0.9661 - val_loss: 0.2229 - val_acc: 0.9317\n",
      "Epoch 40/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1214 - acc: 0.9693\n",
      "Epoch 00040: val_acc improved from 0.93398 to 0.93463, saving model to M2-weights-improvement-40-0.93.hdf5\n",
      "27810/27810 [==============================] - 231s 8ms/sample - loss: 0.1214 - acc: 0.9693 - val_loss: 0.2290 - val_acc: 0.9346\n",
      "Epoch 41/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1189 - acc: 0.9709\n",
      "Epoch 00041: val_acc improved from 0.93463 to 0.93657, saving model to M2-weights-improvement-41-0.94.hdf5\n",
      "27810/27810 [==============================] - 226s 8ms/sample - loss: 0.1189 - acc: 0.9709 - val_loss: 0.2269 - val_acc: 0.9366\n",
      "Epoch 42/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1070 - acc: 0.9753\n",
      "Epoch 00042: val_acc did not improve from 0.93657\n",
      "27810/27810 [==============================] - 225s 8ms/sample - loss: 0.1070 - acc: 0.9753 - val_loss: 0.2561 - val_acc: 0.9320\n",
      "Epoch 43/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1126 - acc: 0.9717\n",
      "Epoch 00043: val_acc did not improve from 0.93657\n",
      "27810/27810 [==============================] - 225s 8ms/sample - loss: 0.1126 - acc: 0.9717 - val_loss: 0.2314 - val_acc: 0.9366\n",
      "Epoch 44/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1092 - acc: 0.9741\n",
      "Epoch 00044: val_acc improved from 0.93657 to 0.93689, saving model to M2-weights-improvement-44-0.94.hdf5\n",
      "27810/27810 [==============================] - 234s 8ms/sample - loss: 0.1092 - acc: 0.9741 - val_loss: 0.2343 - val_acc: 0.9369\n",
      "Epoch 45/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1077 - acc: 0.9757\n",
      "Epoch 00045: val_acc did not improve from 0.93689\n",
      "27810/27810 [==============================] - 227s 8ms/sample - loss: 0.1077 - acc: 0.9757 - val_loss: 0.3187 - val_acc: 0.9068\n",
      "Epoch 46/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1022 - acc: 0.9753\n",
      "Epoch 00046: val_acc improved from 0.93689 to 0.93948, saving model to M2-weights-improvement-46-0.94.hdf5\n",
      "27810/27810 [==============================] - 224s 8ms/sample - loss: 0.1022 - acc: 0.9753 - val_loss: 0.2202 - val_acc: 0.9395\n",
      "Epoch 47/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.1013 - acc: 0.9766\n",
      "Epoch 00047: val_acc did not improve from 0.93948\n",
      "27810/27810 [==============================] - 225s 8ms/sample - loss: 0.1013 - acc: 0.9766 - val_loss: 0.2163 - val_acc: 0.9366\n",
      "Epoch 48/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0974 - acc: 0.9777\n",
      "Epoch 00048: val_acc improved from 0.93948 to 0.94045, saving model to M2-weights-improvement-48-0.94.hdf5\n",
      "27810/27810 [==============================] - 224s 8ms/sample - loss: 0.0974 - acc: 0.9777 - val_loss: 0.2315 - val_acc: 0.9405\n",
      "Epoch 49/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0959 - acc: 0.9785\n",
      "Epoch 00049: val_acc improved from 0.94045 to 0.94304, saving model to M2-weights-improvement-49-0.94.hdf5\n",
      "27810/27810 [==============================] - 229s 8ms/sample - loss: 0.0959 - acc: 0.9785 - val_loss: 0.2356 - val_acc: 0.9430\n",
      "Epoch 50/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0999 - acc: 0.9775\n",
      "Epoch 00050: val_acc improved from 0.94304 to 0.94531, saving model to M2-weights-improvement-50-0.95.hdf5\n",
      "27810/27810 [==============================] - 227s 8ms/sample - loss: 0.0999 - acc: 0.9775 - val_loss: 0.1933 - val_acc: 0.9453\n",
      "Epoch 51/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0938 - acc: 0.9793\n",
      "Epoch 00051: val_acc did not improve from 0.94531\n",
      "27810/27810 [==============================] - 226s 8ms/sample - loss: 0.0938 - acc: 0.9793 - val_loss: 0.2228 - val_acc: 0.9395\n",
      "Epoch 52/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0916 - acc: 0.9795\n",
      "Epoch 00052: val_acc did not improve from 0.94531\n",
      "27810/27810 [==============================] - 234s 8ms/sample - loss: 0.0916 - acc: 0.9795 - val_loss: 0.2778 - val_acc: 0.9210\n",
      "Epoch 53/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0843 - acc: 0.9828\n",
      "Epoch 00053: val_acc did not improve from 0.94531\n",
      "27810/27810 [==============================] - 231s 8ms/sample - loss: 0.0843 - acc: 0.9828 - val_loss: 0.2177 - val_acc: 0.9440\n",
      "Epoch 54/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0856 - acc: 0.9817\n",
      "Epoch 00054: val_acc improved from 0.94531 to 0.94660, saving model to M2-weights-improvement-54-0.95.hdf5\n",
      "27810/27810 [==============================] - 227s 8ms/sample - loss: 0.0856 - acc: 0.9817 - val_loss: 0.2231 - val_acc: 0.9466\n",
      "Epoch 55/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0872 - acc: 0.9817\n",
      "Epoch 00055: val_acc did not improve from 0.94660\n",
      "27810/27810 [==============================] - 224s 8ms/sample - loss: 0.0872 - acc: 0.9817 - val_loss: 0.2040 - val_acc: 0.9463\n",
      "Epoch 56/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0847 - acc: 0.9827\n",
      "Epoch 00056: val_acc improved from 0.94660 to 0.94693, saving model to M2-weights-improvement-56-0.95.hdf5\n",
      "27810/27810 [==============================] - 242s 9ms/sample - loss: 0.0847 - acc: 0.9827 - val_loss: 0.2042 - val_acc: 0.9469\n",
      "Epoch 57/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0859 - acc: 0.9817\n",
      "Epoch 00057: val_acc did not improve from 0.94693\n",
      "27810/27810 [==============================] - 239s 9ms/sample - loss: 0.0859 - acc: 0.9817 - val_loss: 0.2196 - val_acc: 0.9395\n",
      "Epoch 58/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0816 - acc: 0.9837\n",
      "Epoch 00058: val_acc did not improve from 0.94693\n",
      "\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "27810/27810 [==============================] - 232s 8ms/sample - loss: 0.0816 - acc: 0.9837 - val_loss: 0.2362 - val_acc: 0.9440\n",
      "Epoch 59/200\n",
      "27810/27810 [==============================] - ETA: 0s - loss: 0.0526 - acc: 0.9933\n",
      "Epoch 00059: val_acc improved from 0.94693 to 0.95146, saving model to M2-weights-improvement-59-0.95.hdf5\n",
      "27810/27810 [==============================] - 232s 8ms/sample - loss: 0.0526 - acc: 0.9933 - val_loss: 0.2132 - val_acc: 0.9515\n",
      "Epoch 60/200\n",
      "20480/27810 [=====================>........] - ETA: 1:00 - loss: 0.0471 - acc: 0.9952"
     ]
    }
   ],
   "source": [
    "# Training the model\n",
    "#model2.load_weights(\"M2-weights-improvement-23-0.70.hdf5\")\n",
    "history=model2.fit(X_train,\n",
    "          Y_train,\n",
    "          batch_size=batch_size,\n",
    "          validation_split=0.1,\n",
    "          validation_data=None,\n",
    "          shuffle=True,\n",
    "          epochs=epochs,\n",
    "          callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**绘制acc 和loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########画图\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "acc = history.history['acc']     #获取训练集准确性数据\n",
    "val_acc = history.history['val_acc']    #获取验证集准确性数据\n",
    "loss = history.history['loss']          #获取训练集错误值数据\n",
    "val_loss = history.history['val_loss']  #获取验证集错误值数据\n",
    "font = {\n",
    "    'family' : 'Bitstream Vera Sans',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "width = 12\n",
    "height = 8\n",
    "plt.figure(figsize=(width, height))\n",
    "epochs = range(1,len(acc)+1)\n",
    "plt.plot(epochs,acc,'r',label='Trainning acc',linewidth=2)     #以epochs为横坐标，以训练集准确性为纵坐标\n",
    "plt.plot(epochs,val_acc,'b--',label='Vaildation acc',linewidth=2) #以epochs为横坐标，以验证集准确性为纵坐标\n",
    "plt.legend(loc='best', shadow=True)   #绘制图例，即标明图中的线段代表何种含义\n",
    "plt.title(\"Training session's progress over epochs\")\n",
    "plt.ylabel('Training Progress (Accuracy values)')\n",
    "plt.xlabel('Training epochs')\n",
    "\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.plot(epochs,loss,'r',label='Trainning loss',linewidth=2)\n",
    "plt.plot(epochs,val_loss,'b--',label='Vaildation loss',linewidth=2)\n",
    "plt.legend(loc='best', shadow=True)   #绘制图例，即标明图中的线段代表何种含义\n",
    "plt.title(\"Training session's progress over epochs\")\n",
    "plt.ylabel('Training Progress (Loss values)')\n",
    "plt.xlabel('Training epochs') \n",
    "plt.show()    #显示所有图表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "plt.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model2.load_weights(\"M2-weights-improvement-45-0.97.hdf5\")\n",
    "model2.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "scores = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# confusion matrix\n",
    "Y_pred=model2.predict_classes(X_test)\n",
    "print(Y_pred.shape)\n",
    "# Y_pred=np.transpose([Y_pred])\n",
    "# print(Y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_cmap=plt.cm.Greens\n",
    "cm = confusion_matrix(Y_test,Y_pred)\n",
    "\n",
    "\n",
    "print('| Confusion Matrix |')\n",
    "print('--------------------')\n",
    "print('\\n {}'.format(cm))\n",
    "class_labels=['Pre','Mid','Post']\n",
    "# plot confusin matrix\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.grid(b=False)\n",
    "plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix', cmap = cm_cmap)\n",
    "plt.show()\n",
    "class_labels=[0,1,2]\n",
    "# get classification report\n",
    "print('| Classifiction Report |')\n",
    "print('-------------------------')\n",
    "classification_report = metrics.classification_report(Y_test,Y_pred,labels =class_labels)\n",
    "# store report in results\n",
    "\n",
    "\n",
    "print(classification_report)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
